/////////////////////////////////////////////////////////////////////
/// @file AVCodeHelper.cpp
/// @brief 编码辅助类实现
/// 
/// @author andy
/// @version 1.0
/// @date 2021.4.6
/////////////////////////////////////////////////////////////////////

#include "stdafx.h"
#include "AVCodeHelper.h"
#include "FrameBuffer.h"


void FFmpegLogFunc(void* /*ptr*/, int /*level*/, const char* /*fmt*/, va_list /*vl*/)
{
	//char* szBuffer = new char[1024 * 100];

	//if (nullptr != szBuffer)
	//{
	//	sprintf_s(szBuffer, 1024 * 100, fmt, vl);

	//	LOG_ERROR("level =%d,%s", level, szBuffer);
	//	delete[]szBuffer;
	//}
}

CAVCodeHelper::CAVCodeHelper(EncodeCallback fnEncodeCallback)
	:m_fnEncodeCallback(fnEncodeCallback)
{
}

CAVCodeHelper::CAVCodeHelper(DecodeCallback fnDecodeCallback)
	: m_fnDecodeCallback(fnDecodeCallback)
{
}

CAVCodeHelper::~CAVCodeHelper()
{
	Destroy();
}



// ********************************************************************************
/// <summary>
/// 初始化
/// </summary>
/// <param name="nMode">工作模式</param>
/// <param name="nWidth">帧的宽度</param>
/// <param name="nHeight">帧的高度</param>
/// <param name="AV_PIX_FMT_YUV420P"></param>
/// <nReturns></nReturns>
/// <created>Andy,2021/4/6</created>
/// <changed>Andy,2021/4/6</changed>
// ********************************************************************************
bool CAVCodeHelper::Construct(
	const WORKING_MODE nMode
	, const unsigned int nWidth
	, const unsigned int nHeight
	, const AVPixelFormat nPixelFormat)
{
	std::unique_lock<std::mutex> objAutoLocker(m_objMutex);
	bool bResult = false;

	SetConstructed(false);
	SetMode(nMode);
	SetWidth(nWidth);
	SetHeight(nHeight);
	
	LOG_ERROR("CAVCodeHelper::Construct(%d * %d)",	GetWidth(), GetHeight());

	av_log_set_callback(FFmpegLogFunc);

	avdevice_register_all();

	if (GetMode() == WM_ENCODE)
	{
		m_pAVCodec = avcodec_find_encoder(AV_CODEC_ID_H264);
	}
	else
	{
		m_pAVCodec = avcodec_find_decoder(AV_CODEC_ID_H264);
	}

	CHECK_POINTER_EX(m_pAVCodec, false);

	m_pAVCodecContext = avcodec_alloc_context3(m_pAVCodec);
	CHECK_POINTER_EX(m_pAVCodec, false);

	if (GetMode() == WM_ENCODE)
	{
		m_pAVCodecContext->flags |= AV_CODEC_FLAG_QSCALE;

		switch (GetImageQuality())
		{
		case CPrjSettings::IQT_DISPLAY_SPEED_PRIORITY:
			m_pAVCodecContext->bit_rate = 1000000;   // 比特率越高，传送的数据越大,越清晰265可以设400k，264需要800k,网络传输变得不清晰了，需要加大到1500K
			m_pAVCodecContext->rc_min_rate = 500000;
			m_pAVCodecContext->rc_max_rate = 1000000;
			m_pAVCodecContext->bit_rate_tolerance = 1000000;
			break;

		default:
			m_pAVCodecContext->bit_rate = 3000000;   // 比特率越高，传送的数据越大,越清晰265可以设400k，264需要800k,网络传输变得不清晰了，需要加大到1500K
			m_pAVCodecContext->rc_min_rate = 800000;
			m_pAVCodecContext->rc_max_rate = 3000000;
			m_pAVCodecContext->bit_rate_tolerance = 3000000;
		}



		//
		m_pAVCodecContext->time_base = { 1, 30 };
		m_pAVCodecContext->width = GetWidth();
		m_pAVCodecContext->height = GetHeight();

		////每100帧插入1个I帧，I帧越少，视频越小
		m_pAVCodecContext->gop_size = 100;

		//（函数输出的延时仅仅跟max_b_frames的设置有关，想进行实时编码，将max_b_frames设置为0便没有编码延时了）
		// 设置 B 帧最大的数量，B帧为视频图片空间的前后预测帧， B 帧相对于 I、P 帧来说，压缩率比较大，采用多编码 B 帧提高清晰度
		m_pAVCodecContext->max_b_frames = 0;

		// 不能采用多线程，会导致画面延迟
		//m_pAVCodecContext->thread_count = std::thread::hardware_concurrency();
		m_pAVCodecContext->pix_fmt = AV_PIX_FMT_YUV420P;
		m_pAVCodecContext->codec_id = m_pAVCodec->id;
		m_pAVCodecContext->codec_type = AVMEDIA_TYPE_VIDEO;

		//av_opt_set(m_pAVCodecContext->priv_data, "x265-params", "qp=20", 0);
		av_opt_set(m_pAVCodecContext->priv_data, "preset", "superfast", 0);
		av_opt_set(m_pAVCodecContext->priv_data, "tune", "zerolatency", 0);

		int nResult = avcodec_open2(m_pAVCodecContext, m_pAVCodec, NULL);

		if (nResult >= 0)
		{
			m_pAVFrame = av_frame_alloc();
			CHECK_POINTER_EX(m_pAVFrame, false);
			m_pAVFrame->format = AV_PIX_FMT_YUV420P;
			m_pAVFrame->width = GetWidth();
			m_pAVFrame->height = GetHeight();

			const int nFrameSize = av_image_get_buffer_size(AV_PIX_FMT_YUV420P, GetWidth(), GetHeight(), 1);

			m_objOutBuffer.Allocate(nFrameSize);
			nResult = av_image_fill_arrays(
				m_pAVFrame->data
				, m_pAVFrame->linesize
				, m_objOutBuffer.GetBufferHeadPtr()
				, AV_PIX_FMT_YUV420P
				, GetWidth()
				, GetHeight()
				, 1);

			if (nResult > 0)
			{
				m_pAVPacket = av_packet_alloc();
				CHECK_POINTER_EX(m_pAVPacket, false);
				av_init_packet(m_pAVPacket);

				m_pImgConvertContext = sws_getContext(
					m_pAVCodecContext->width
					, m_pAVCodecContext->height
					, nPixelFormat
					, m_pAVCodecContext->width
					, m_pAVCodecContext->height
					, AV_PIX_FMT_YUV420P
					, SWS_BICUBIC
					, NULL
					, NULL
					, NULL);
				
				bResult = true;
			}
		}
		else
		{
			LOG_ERROR("Fail to run avcodec_open2 (error = %d)", nResult);
		}
	}
	else
	{
		m_pAVCodecContext->gop_size = 2;
		m_pAVCodecContext->max_b_frames = 0;
		//m_pAVCodecContext->thread_count = std::thread::hardware_concurrency();
		//av_opt_set(m_pAVCodecContext->priv_data, "x265-params", "qp=20", 0);
		av_opt_set(m_pAVCodecContext->priv_data, "preset", "superfast", 0);
		av_opt_set(m_pAVCodecContext->priv_data, "tune", "zerolatency", 0);

		int nResult = avcodec_open2(m_pAVCodecContext, m_pAVCodec, NULL);

		if (nResult >= 0)
		{
			m_pCodecParserContext = av_parser_init(m_pAVCodec->id);

			if (nullptr != m_pCodecParserContext)
			{
				const int nFrameSize = av_image_get_buffer_size(nPixelFormat, GetWidth(), GetHeight(), 16);

				if (m_objOutBuffer.GetSize() < nFrameSize)
				{
					m_objOutBuffer.Allocate(nFrameSize);
				}
				else
				{
					memset(m_objOutBuffer.GetBufferFreeHeadPtr(), 0, m_objOutBuffer.GetSize());
				}

				m_pAVFrame = av_frame_alloc();
				CHECK_POINTER_EX(m_pAVFrame, false);

				m_pAVPacket = av_packet_alloc();
				CHECK_POINTER_EX(m_pAVPacket, false);
				av_init_packet(m_pAVPacket);

				m_pImgConvertContext = sws_getContext(
					 GetWidth()
					, GetHeight()
					, AV_PIX_FMT_YUV420P
					, GetWidth()
					, GetHeight()
					, nPixelFormat
					, SWS_BICUBIC
					, NULL
					, NULL
					, NULL);


				bResult = true;		
			}
			else
			{
				LOG_ERROR("Fail to run av_parser_init");
			}
		}
		else
		{
			LOG_ERROR("Fail to run avcodec_open2 (error = %d)", nResult);
		}
	}		

	SetConstructed(bResult);

	return bResult;
}

// ********************************************************************************
/// <summary>
/// 释放
/// </summary>
/// <created>Andy,2021/4/10</created>
/// <changed>Andy,2021/4/10</changed>
// ********************************************************************************
void CAVCodeHelper::Destroy()
{
	std::unique_lock<std::mutex> objAutoLocker(m_objMutex);

	if (nullptr != m_pAVCodecContext)
	{
		avcodec_close(m_pAVCodecContext);
		avcodec_free_context(&m_pAVCodecContext);
		m_pAVCodecContext = nullptr;
	}

	if (nullptr != m_pAVPacket)
	{
		av_packet_free(&m_pAVPacket);
		m_pAVPacket = nullptr;
	}


	if (nullptr != m_pAVFrame)
	{
		av_frame_free(&m_pAVFrame);
		m_pAVFrame = nullptr;
	}

	if (nullptr != m_pCodecParserContext)
	{
		av_parser_close(m_pCodecParserContext);
		m_pCodecParserContext = nullptr;
	}

	if (nullptr != m_pImgConvertContext)
	{
		sws_freeContext(m_pImgConvertContext);
		m_pImgConvertContext = nullptr;
	}
}


// ********************************************************************************
/// <summary>
/// 查询错误消息
/// </summary>
/// <param name="nError"></param>
/// <returns></returns>
/// <created>Andy,2021/4/7</created>
/// <changed>Andy,2021/4/7</changed>
// ********************************************************************************
const TCHAR* CAVCodeHelper::QueryErrorMsg(const int nError)
{
	switch (AVUNERROR(nError))
	{
	case EAGAIN:
		return _T("EAGAIN");
		break;

	case AVERROR_EOF:
		return _T("AVERROR_EOF");
		break;

	case EINVAL:
		return _T("EINVAL");
		break;

	case ENOMEM:
		return _T("ENOMEM");
		break;
	}

	return nullptr;
}


// ********************************************************************************
/// <summary>
/// 编码
/// </summary>
/// <param name="pFrameBuffer">指向需要编码图像数据</param>
/// <nReturns></nReturns>
/// <created>Andy,2021/4/6</created>
/// <changed>Andy,2021/4/6</changed>
// ********************************************************************************
bool CAVCodeHelper::Encode(const CFrameBuffer* pFrameBuffer)
{
	std::unique_lock<std::mutex> objAutoLocker(m_objMutex);

	assert(GetMode() == WM_ENCODE);
	assert(nullptr != m_pAVCodecContext);
	assert(nullptr != m_pAVPacket);
	assert(nullptr != m_pAVPacket);
	assert(nullptr != m_pAVFrame);

	CHECK_POINTER_EX(pFrameBuffer, false);

	if (!GetConstructed())
	{
		return false;
	}

	if ((pFrameBuffer->m_objDimension.width != int(GetWidth()))
		|| (pFrameBuffer->m_objDimension.height != int(GetHeight())))
	{
		LOG_ERROR("Size mismatch(%d * %d->%d * %d)",
			GetWidth()
			, GetHeight()
			, pFrameBuffer->m_objDimension.width
			, pFrameBuffer->m_objDimension.height);
		return false;
	}
	
	int arrLinesize[3] = { int(GetWidth() * pFrameBuffer->GetBytesPerPixel()),0,0 };
	uint8_t* arrBGRBuffer[3] = { (uint8_t*)pFrameBuffer->GetBuffer(),nullptr,nullptr };

	const int nSliceHeight = sws_scale(
		m_pImgConvertContext
		, arrBGRBuffer
		, arrLinesize
		, 0
		, GetHeight()
		, m_pAVFrame->data
		, m_pAVFrame->linesize);

	m_pAVFrame->pts = m_pAVFrame->pkt_dts = 0;
	/*m_pAVFrame->pts = 0;av_rescale_q_rnd(
		frameNumber
		, m_pAVCodecContext->time_base
		, avStream->time_base
		, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX))*/
	m_pAVFrame->pkt_duration = 0;
	m_pAVFrame->pkt_pos = -1;

	bool bResult = false;
	int nResult = avcodec_send_frame(m_pAVCodecContext, m_pAVFrame);

	if (nResult >= 0)
	{
		while (nResult >= 0)
		{
			nResult = avcodec_receive_packet(m_pAVCodecContext, m_pAVPacket);
			
			if (nResult == AVERROR(EAGAIN) || nResult == AVERROR_EOF)
			{
				//LOG_ERROR("Error during encoding (err = %d)", nResult);
				break;
			}
			else if (nResult < 0) 
			{
				LOG_ERROR("Error during encoding (err = %d)", nResult);
				break;
			}

			m_fnEncodeCallback(m_pAVPacket);
			av_packet_unref(m_pAVPacket);
			bResult = true;
		}
	}
	else
	{
		LOG_ERROR("Fail to send a frame for encoding (err = %d)", nResult);
	}


	return bResult;
}

// ********************************************************************************
/// <summary>
/// 解码
/// </summary>
/// <param name="pBuffer">指向被解码的数据</param>
/// <param name="nLen">被解码的数据常量</param>
/// <nReturns></nReturns>
/// <created>Andy,2021/4/6</created>
/// <changed>Andy,2021/4/6</changed>
// ********************************************************************************
bool CAVCodeHelper::Decode(const unsigned char* pBuffer, const unsigned int nLen)
{
	std::unique_lock<std::mutex> objAutoLocker(m_objMutex);

	assert(GetMode() == WM_DECODE);
	assert(nullptr != m_pAVCodecContext);
	assert(nullptr != m_pCodecParserContext);
	assert(nullptr != m_pAVPacket);
	assert(nullptr != m_pAVFrame);
	assert(nullptr != m_pImgConvertContext);

	if (!GetConstructed())
	{
		return false;
	}

	bool bResult = false;
	//int nBytesInputed = 0;

	// 因为收到的刚好时一个数据包，所以此处不需要分离数据包
	m_pAVPacket->data = (uint8_t*)pBuffer;
	m_pAVPacket->size = nLen;

	int nRet = avcodec_send_packet(m_pAVCodecContext, m_pAVPacket);

	if (nRet >= 0)
	{
		do
		{
			nRet = avcodec_receive_frame(m_pAVCodecContext, m_pAVFrame);

			if (nRet == AVERROR(EAGAIN) || nRet == AVERROR_EOF)
			{
				break;
			}
			else if (nRet < 0)
			{
				LOG_ERROR("Error during decoding(error = %d)", nRet);
				break;
			}

			if (m_objOutBuffer.GetBufferHeadPtr() != nullptr)
			{
				int arrLinesize[3] = { int(GetWidth() * 4),0,0 };
				uint8_t* arrBGRBuffer[3] = { m_objOutBuffer.GetBufferHeadPtr(),nullptr,nullptr };

				sws_scale(m_pImgConvertContext, m_pAVFrame->data, m_pAVFrame->linesize, 0, m_pAVFrame->height, arrBGRBuffer, arrLinesize);
				m_fnDecodeCallback(m_objOutBuffer.GetBufferHeadPtr(), m_pAVFrame->width, m_pAVFrame->height);
				bResult = true;
			}
			else
			{
				LOG_ERROR("Invalid buffer!");
			}

		} while (nRet >= 0);
	}
	else
	{
		LOG_ERROR("Error sending a packet for decoding (error = %s)", QueryErrorMsg(AVUNERROR(nRet)));
	}


	return bResult;
}
